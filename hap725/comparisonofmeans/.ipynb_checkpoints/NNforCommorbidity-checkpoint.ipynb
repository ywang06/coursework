{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='example.log',level=logging.DEBUG)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Age', 'Sex', 'tAssess', 'Followed', 'DaysFirst', 'DaysLast',\n",
      "       'uEat', 'uSit', 'uGroom', 'uToilet', 'uBathe', 'uWalk', 'uDress',\n",
      "       'uBowel', 'uUrine', 'Alive', 'AssessID', 'Dead6Months'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n",
      "[[1.         0.         1.         0.         0.         0.\n",
      "  1.         1.         1.         0.79036169 0.20963831]\n",
      " [1.         1.         1.         1.         0.         0.\n",
      "  1.         1.         1.         0.81393271 0.18606729]\n",
      " [0.         1.         0.         0.         1.         0.\n",
      "  1.         1.         0.         0.86904228 0.13095772]\n",
      " [0.         1.         0.         1.         0.         1.\n",
      "  1.         1.         0.         0.86688071 0.13311929]\n",
      " [1.         1.         1.         1.         1.         0.\n",
      "  0.         0.         0.         0.74769009 0.25230991]\n",
      " [1.         0.         0.         0.         0.         1.\n",
      "  0.         1.         1.         0.71940856 0.28059144]\n",
      " [0.         1.         1.         0.         0.         1.\n",
      "  1.         1.         0.         0.76822023 0.23177977]\n",
      " [1.         0.         1.         0.         0.         1.\n",
      "  1.         0.         1.         0.66889432 0.33110568]\n",
      " [0.         1.         1.         1.         0.         1.\n",
      "  1.         0.         1.         0.85608925 0.14391075]\n",
      " [1.         0.         1.         1.         0.         1.\n",
      "  1.         0.         1.         0.68631849 0.31368151]\n",
      " [0.         1.         0.         0.         1.         0.\n",
      "  0.         0.         1.         0.90025984 0.09974016]\n",
      " [0.         1.         0.         0.         0.         1.\n",
      "  1.         0.         1.         0.90910963 0.09089037]\n",
      " [1.         0.         0.         1.         1.         0.\n",
      "  1.         1.         1.         0.84802066 0.15197934]\n",
      " [1.         0.         0.         0.         1.         0.\n",
      "  1.         1.         0.         0.72382239 0.27617761]\n",
      " [1.         1.         1.         1.         1.         0.\n",
      "  0.         1.         0.         0.68468275 0.31531725]\n",
      " [0.         1.         0.         1.         1.         0.\n",
      "  0.         1.         1.         0.88804179 0.11195821]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         1.         1.         0.84421153 0.15578847]\n",
      " [1.         1.         0.         1.         1.         1.\n",
      "  0.         1.         0.         0.69632744 0.30367256]\n",
      " [0.         1.         1.         1.         0.         0.\n",
      "  0.         0.         0.         0.85544118 0.14455882]\n",
      " [0.         1.         1.         0.         0.         1.\n",
      "  0.         1.         0.         0.79748779 0.20251221]\n",
      " [1.         1.         0.         0.         1.         1.\n",
      "  0.         0.         0.         0.71437034 0.28562966]\n",
      " [0.         1.         1.         1.         0.         0.\n",
      "  1.         0.         0.         0.84495033 0.15504967]\n",
      " [1.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.79501049 0.20498951]\n",
      " [1.         0.         0.         1.         0.         0.\n",
      "  1.         0.         0.         0.71831832 0.28168168]\n",
      " [1.         1.         1.         1.         0.         0.\n",
      "  1.         0.         0.         0.74770996 0.25229004]\n",
      " [1.         0.         1.         0.         0.         1.\n",
      "  0.         1.         1.         0.64093437 0.35906563]\n",
      " [1.         1.         1.         0.         1.         1.\n",
      "  0.         0.         1.         0.62746809 0.37253191]\n",
      " [0.         1.         0.         1.         1.         0.\n",
      "  1.         0.         1.         0.88968969 0.11031031]\n",
      " [1.         1.         0.         0.         1.         0.\n",
      "  1.         0.         0.         0.77435358 0.22564642]\n",
      " [1.         1.         0.         0.         1.         1.\n",
      "  1.         1.         1.         0.77409973 0.22590027]\n",
      " [0.         1.         0.         1.         0.         0.\n",
      "  1.         0.         0.         0.8752442  0.1247558 ]\n",
      " [1.         1.         0.         1.         1.         0.\n",
      "  1.         0.         0.         0.79098596 0.20901404]\n",
      " [1.         0.         0.         0.         0.         0.\n",
      "  1.         1.         0.         0.70237497 0.29762503]\n",
      " [0.         1.         1.         0.         0.         0.\n",
      "  1.         1.         1.         0.84740912 0.15259088]\n",
      " [1.         1.         0.         0.         1.         1.\n",
      "  0.         1.         0.         0.65811186 0.34188814]\n",
      " [1.         1.         0.         1.         1.         1.\n",
      "  1.         0.         1.         0.80023732 0.19976268]\n",
      " [0.         1.         0.         0.         0.         1.\n",
      "  1.         1.         1.         0.85359897 0.14640103]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"/Users/yingwang/Google Drive/Study2017/GeorgeMasonUniversity/Fall2018/HAP725/Week12/interpretValue/all_data.csv\"\n",
    "df_all = pd.read_csv(open(filename,'r',errors='ignore'),skip_blank_lines=True, error_bad_lines=False,low_memory=False)\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "df_all = df_all.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_all = df_all.sample(frac=1)\n",
    "print(df_all.columns)\n",
    "query_str_positive = \"Dead6Months >= 1\"\n",
    "query_str_negative = \"Dead6Months < 0.8\" \n",
    "df_s2 = df_all[['Dead6Months']] \n",
    "df_s1 = df_all[['uEat', 'uSit', 'uGroom', 'uToilet', 'uBathe', 'uWalk', 'uDress',\n",
    "       'uBowel', 'uUrine']]\n",
    "\n",
    "s1_training = df_s1.values\n",
    "s2_training = df_s2.values\n",
    "\n",
    "df_test = df_s1.drop_duplicates(subset=['uEat', 'uSit', 'uGroom', 'uToilet', 'uBathe', 'uWalk', 'uDress',\n",
    "       'uBowel', 'uUrine'], keep=False)\n",
    "\n",
    "s_test = df_test.values\n",
    "\n",
    "# fit model\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 8), random_state=1)\n",
    "clf = MLPClassifier(activation='tanh', alpha=1e-05, batch_size='lbfgs',beta_1=0.9, beta_2=0.999, early_stopping=False,epsilon=1e-08, hidden_layer_sizes=(7, 4), learning_rate='constant',learning_rate_init=0.001, max_iter=10000, momentum=0.9,nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,warm_start=False)\n",
    "clf.fit(s1_training, s2_training)                         \n",
    "\n",
    "print(\"finished training\")\n",
    "\n",
    "\n",
    "predicted_result = clf.predict(s1_training)\n",
    "predicted_prob = clf.predict_proba(s1_training)\n",
    "\n",
    "type_result = clf.predict_proba(s_test)\n",
    "\n",
    "print(np.concatenate((s_test, type_result), axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 9)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
